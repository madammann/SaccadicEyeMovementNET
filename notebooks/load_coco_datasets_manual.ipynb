{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "load_coco_datasets_manually.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install the dataset\n"
      ],
      "metadata": {
        "id": "a6twaCXVI7KH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install CocoDataset==0.1.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkXyQ264I-6B",
        "outputId": "71160936-aa11-4b92-ad61-437ebec19fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting CocoDataset==0.1.2\n",
            "  Downloading CocoDataset-0.1.2-py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from CocoDataset==0.1.2) (2.0.4)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->CocoDataset==0.1.2) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pycocotools->CocoDataset==0.1.2) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->CocoDataset==0.1.2) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->CocoDataset==0.1.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->CocoDataset==0.1.2) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools->CocoDataset==0.1.2) (3.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools->CocoDataset==0.1.2) (1.15.0)\n",
            "Installing collected packages: CocoDataset\n",
            "Successfully installed CocoDataset-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we build the data with https://www.tensorflow.org/datasets/api_docs/python/tfds/folder_dataset/ImageFolder, \n",
        "\n",
        "tfds.folder_dataset.ImageFolder, needs to have an specific stracture. (check the documentation)\n",
        "\n",
        "\n",
        "Now, we create the stracture, but befire we need to mount the drive from left side panel-> files -> click mount drive"
      ],
      "metadata": {
        "id": "uuHTUhKUdK_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfsH5qWwObBF",
        "outputId": "c0a2a9e6-b65d-47da-a2af-07fbd80da161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/coco_data/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mount the drive and select the directory\n",
        "\n",
        "first, we set the training directory"
      ],
      "metadata": {
        "id": "G_G-gK6TQpDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/coco_data/train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "735n4Xq6PrPJ",
        "outputId": "96a5cd45-fa79-4e24-fdd2-0c9e0456c3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/coco_data/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the annotations"
      ],
      "metadata": {
        "id": "TK6ClLjhJWdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
        "!unzip /content/drive/MyDrive/coco_data/train/annotations_trainval2014.zip\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuLsPba0JYth",
        "outputId": "71c6878d-2431-44d3-fa49-3764015a224f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-14 21:25:11--  http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 54.231.137.193\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|54.231.137.193|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252872794 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2014.zip.2’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.16M  41.9MB/s    in 6.0s    \n",
            "\n",
            "2022-03-14 21:25:17 (40.1 MB/s) - ‘annotations_trainval2014.zip.2’ saved [252872794/252872794]\n",
            "\n",
            "Archive:  /content/drive/MyDrive/coco_data/train/annotations_trainval2014.zip\n",
            "  inflating: annotations/instances_train2014.json  \n",
            "  inflating: annotations/instances_val2014.json  \n",
            "  inflating: annotations/person_keypoints_train2014.json  \n",
            "  inflating: annotations/person_keypoints_val2014.json  \n",
            "  inflating: annotations/captions_train2014.json  \n",
            "  inflating: annotations/captions_val2014.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "class names for downloading\n"
      ],
      "metadata": {
        "id": "nqG9j0Y2JkZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['airplane', \"apple\", \"banana\", \"boat\", \"bus\", \"car\",\"person\",\"bicycle\",\"bird\",\"book\"]"
      ],
      "metadata": {
        "id": "o5aVmacEJjgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "write the function to download the class with annotations and save it to content folder"
      ],
      "metadata": {
        "id": "CgDdafVuKaNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from coco_dataset import coco_dataset_download as cocod\n",
        "\n",
        "\n",
        "def manual_download(names):\n",
        "  class_name=names  #class name example \n",
        "  images_count=500       #count of images  \n",
        "  annotations_path='/content/drive/MyDrive/coco_data/train/annotations/instances_train2014.json' #path of coco dataset annotations \n",
        "  #call download function \n",
        "  cocod.coco_dataset_download(class_name,images_count,annotations_path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bFPPoft8KZU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in classes:\n",
        "  manual_download(i)\n",
        "  "
      ],
      "metadata": {
        "id": "oT7_1AF7LCaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for removing the annotations\n",
        "!rm -rf annotations"
      ],
      "metadata": {
        "id": "6U7q_HUFbCMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we set the test directory and download the daata these"
      ],
      "metadata": {
        "id": "Pi1MqBPxa-N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/coco_data/test"
      ],
      "metadata": {
        "id": "5GpdzaiTa9d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfce4fe-46ce-4510-88db-7390b16b8cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/coco_data/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
        "!unzip /content/drive/MyDrive/coco_data/test/annotations_trainval2014.zip\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LLLKppTWa3iG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0052630e-a417-480a-f886-d5df0f05bcae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-14 21:51:41--  http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.20.139\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.20.139|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252872794 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2014.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.16M  36.0MB/s    in 6.5s    \n",
            "\n",
            "2022-03-14 21:51:48 (37.2 MB/s) - ‘annotations_trainval2014.zip’ saved [252872794/252872794]\n",
            "\n",
            "Archive:  /content/drive/MyDrive/coco_data/test/annotations_trainval2014.zip\n",
            "  inflating: annotations/instances_train2014.json  \n",
            "  inflating: annotations/instances_val2014.json  \n",
            "  inflating: annotations/person_keypoints_train2014.json  \n",
            "  inflating: annotations/person_keypoints_val2014.json  \n",
            "  inflating: annotations/captions_train2014.json  \n",
            "  inflating: annotations/captions_val2014.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from coco_dataset import coco_dataset_download as cocod\n",
        "\n",
        "\n",
        "def manual_download(names):\n",
        "  class_name=names  #class name example \n",
        "  images_count=30       #count of images  \n",
        "  annotations_path='/content/drive/MyDrive/coco_data/test/annotations/instances_val2014.json' #path of coco dataset annotations \n",
        "  #call download function \n",
        "  cocod.coco_dataset_download(class_name,images_count,annotations_path)\n"
      ],
      "metadata": {
        "id": "XVBkZ5z5bLCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in classes:\n",
        "  manual_download(i)"
      ],
      "metadata": {
        "id": "PRorjyG9bLEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for removing the annotations\n",
        "!rm -rf annotations"
      ],
      "metadata": {
        "id": "qDpQWBKgcj8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we build the data from folder as tensors\n"
      ],
      "metadata": {
        "id": "YMz3iNQaMenx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "builder = tfds.ImageFolder('/content/drive/MyDrive/coco_data/')\n",
        "print(builder.info)  # num examples, labels... are automatically calculated\n",
        "dataset = builder.as_dataset(shuffle_files=True, as_supervised = True)\n",
        "train_ds, test_ds = dataset[\"train\"], dataset[\"test\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wilDs_EiKirG",
        "outputId": "f809301d-14e4-4e37-ddd3-5384d80e2bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='image_folder',\n",
            "    version=1.0.0,\n",
            "    description='Generic image classification dataset.',\n",
            "    homepage='https://www.tensorflow.org/datasets/catalog/image_folder',\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
            "        'image/filename': Text(shape=(), dtype=tf.string),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=11),\n",
            "    }),\n",
            "    total_num_examples=5320,\n",
            "    splits={\n",
            "        'test': 310,\n",
            "        'train': 5010,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "to preprocess the data pipeline"
      ],
      "metadata": {
        "id": "taBRdtuTc2lN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def prepare_coco_data(mnist):\n",
        "  #flatten the images into vectors\n",
        "  mnist = mnist.map(lambda img, target: (tf.image.resize(img, [64,64],\n",
        "                                         method = tf.image.ResizeMethod.BILINEAR, \n",
        "                                         preserve_aspect_ratio=False),      target))\n",
        "  \n",
        "  #convert data from uint8 to float32\n",
        "  mnist = mnist.map(lambda img, target: (tf.cast(img, tf.float32), target))\n",
        "  #sloppy input normalization, just bringing image values from range [0, 255] to [-1, 1]\n",
        "  mnist = mnist.map(lambda img, target: ((img/128.)-1., target))\n",
        "  #create one-hot targets\n",
        "  mnist = mnist.map(lambda img, target: (img, tf.one_hot(target, depth=10)))\n",
        "  #cache this progress in memory, as there is no need to redo it; it is deterministic after all\n",
        "  mnist = mnist.cache()\n",
        "  #shuffle, batch, prefetch\n",
        "  mnist = mnist.shuffle(1000)\n",
        "  mnist = mnist.batch(32)\n",
        "  mnist = mnist.prefetch(20)\n",
        "  #return preprocessed dataset\n",
        "  return mnist\n",
        "\n",
        "train_dataset = train_ds.apply(prepare_coco_data)\n",
        "test_dataset = test_ds.apply(prepare_coco_data)"
      ],
      "metadata": {
        "id": "4kCdl0hlLPtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "build the model(demo, just to test the data)"
      ],
      "metadata": {
        "id": "TK2J442Ac1gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=128,kernel_size=3,strides=1,padding='same',activation='relu')\n",
        "        self.batch_norm_1 = tf.keras.layers.BatchNormalization()\n",
        "        self.drop_1 = tf.keras.layers.Dropout(0.5)\n",
        "\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=128,kernel_size=3,strides=1,padding='same',activation='relu')\n",
        "        self.batch_norm_2 = tf.keras.layers.BatchNormalization()\n",
        "        self.drop_2 = tf.keras.layers.Dropout(0.5)\n",
        "\n",
        "        self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=2,strides=2,padding='same')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters=64,kernel_size=3,strides=1,padding='same',activation='relu')\n",
        "        self.batch_norm_3 = tf.keras.layers.BatchNormalization()\n",
        "        self.drop_3 = tf.keras.layers.Dropout(0.75)\n",
        "\n",
        "        self.conv4 = tf.keras.layers.Conv2D(filters=64,kernel_size=3,strides=1,padding='same',activation='relu')\n",
        "        self.batch_norm_4 = tf.keras.layers.BatchNormalization()\n",
        "        self.drop_4 = tf.keras.layers.Dropout(0.75)\n",
        "\n",
        "        self.maxpool2 = tf.keras.layers.MaxPooling2D(pool_size=2,strides=2,padding='same')\n",
        "        self.batch_norm_5 = tf.keras.layers.BatchNormalization()\n",
        "        self.drop_5 = tf.keras.layers.Dropout(0.2)\n",
        "\n",
        "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.out = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x):\n",
        "        #print(x.shape)\n",
        "        x = self.conv1(x)\n",
        "        #print(x.shape)\n",
        "        x = self.batch_norm_1(x)\n",
        "        x = self.drop_1(x)\n",
        "        x = self.conv2(x)\n",
        "        #print(x.shape)\n",
        "        x = self.batch_norm_2(x)\n",
        "        x = self.drop_2(x)\n",
        "        x = self.maxpool(x)\n",
        "        #print(x.shape)\n",
        "        # x = self.batch_norm_3(x)\n",
        "        # x = self.drop_3(x)\n",
        "        # x = self.conv3(x)\n",
        "        # #print(x.shape)\n",
        "        # x = self.conv4(x)\n",
        "        # x = self.batch_norm_4(x)\n",
        "        # x = self.drop_4(x)\n",
        "        #print(x.shape)\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.batch_norm_5(x)\n",
        "        x = self.drop_5(x)\n",
        "        #print(x.shape)\n",
        "        x = self.avgpool(x)\n",
        "        #print(x.shape)\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "    "
      ],
      "metadata": {
        "id": "qcHhBzgbLPwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train steps, takem from complete model train file"
      ],
      "metadata": {
        "id": "BAmS9Dxyc8Sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, input, target, loss_function, optimizer):\n",
        "  # loss_object and optimizer_object are instances of respective tensorflow classes\n",
        "  with tf.GradientTape() as tape:\n",
        "    prediction = model(input)\n",
        "    loss = loss_function(target, prediction)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "def test(model, test_data, loss_function):\n",
        "  # test over complete test data\n",
        "\n",
        "  test_accuracy_aggregator = []\n",
        "  test_loss_aggregator = []\n",
        "\n",
        "  for (input, target) in test_data:\n",
        "    prediction = model(input)\n",
        "    sample_test_loss = loss_function(target, prediction)\n",
        "    sample_test_accuracy =  np.argmax(target, axis=1) == np.argmax(prediction, axis=1)\n",
        "    sample_test_accuracy = np.mean(sample_test_accuracy)\n",
        "    test_loss_aggregator.append(sample_test_loss.numpy())\n",
        "    test_accuracy_aggregator.append(np.mean(sample_test_accuracy))\n",
        "\n",
        "  test_loss = tf.reduce_mean(test_loss_aggregator)\n",
        "  test_accuracy = tf.reduce_mean(test_accuracy_aggregator)\n",
        "\n",
        "  return test_loss, test_accuracy"
      ],
      "metadata": {
        "id": "zKLJyE2vLPxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "#For showcasing we only use a subset of the training and test data (generally use all of the available data!)\n",
        "train_dataset = train_dataset.take(100)\n",
        "test_dataset = test_dataset.take(10)\n",
        "\n",
        "### Hyperparameters\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize the model.\n",
        "model = MyModel()\n",
        "# Initialize the loss: categorical cross entropy. Check out 'tf.keras.losses'.\n",
        "cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "# Initialize the optimizer: ADAM with default parameters. Check out 'tf.keras.optimizers'\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "# Initialize lists for later visualization.\n",
        "train_losses = []\n",
        "\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "#testing once before we begin\n",
        "test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
        "test_losses.append(test_loss)\n",
        "test_accuracies.append(test_accuracy)\n",
        "\n",
        "#check how model performs on train data once before we begin\n",
        "train_loss, _ = test(model, train_dataset, cross_entropy_loss)\n",
        "train_losses.append(train_loss)\n",
        "\n",
        "# We train for num_epochs epochs.\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch: {str(epoch)} starting with accuracy {test_accuracies[-1]}')\n",
        "\n",
        "    #training (and checking in with training)\n",
        "    epoch_loss_agg = []\n",
        "    for input,target in train_dataset:\n",
        "        train_loss = train_step(model, input, target, cross_entropy_loss, optimizer)\n",
        "        epoch_loss_agg.append(train_loss)\n",
        "    \n",
        "    #track training loss\n",
        "    train_losses.append(tf.reduce_mean(epoch_loss_agg))\n",
        "\n",
        "    #testing, so we can track accuracy and test loss\n",
        "    test_loss, test_accuracy = test(model, test_dataset, cross_entropy_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSyXVojZLPzq",
        "outputId": "aa24f6a5-08ca-4229-cd9e-878c354a1213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 starting with accuracy 0.0934659090909091\n",
            "Epoch: 1 starting with accuracy 0.23948863636363638\n",
            "Epoch: 2 starting with accuracy 0.21647727272727274\n",
            "Epoch: 3 starting with accuracy 0.24602272727272725\n",
            "Epoch: 4 starting with accuracy 0.24147727272727276\n",
            "Epoch: 5 starting with accuracy 0.23892045454545455\n",
            "Epoch: 6 starting with accuracy 0.2690340909090909\n",
            "Epoch: 7 starting with accuracy 0.25227272727272726\n",
            "Epoch: 8 starting with accuracy 0.2605113636363636\n",
            "Epoch: 9 starting with accuracy 0.2792613636363636\n",
            "Epoch: 10 starting with accuracy 0.30568181818181817\n",
            "Epoch: 11 starting with accuracy 0.3159090909090909\n",
            "Epoch: 12 starting with accuracy 0.2667613636363636\n",
            "Epoch: 13 starting with accuracy 0.2863636363636364\n",
            "Epoch: 14 starting with accuracy 0.29772727272727273\n",
            "Epoch: 15 starting with accuracy 0.31732954545454545\n",
            "Epoch: 16 starting with accuracy 0.3125\n",
            "Epoch: 17 starting with accuracy 0.31732954545454545\n",
            "Epoch: 18 starting with accuracy 0.30568181818181817\n",
            "Epoch: 19 starting with accuracy 0.31619318181818185\n",
            "Epoch: 20 starting with accuracy 0.2980113636363636\n",
            "Epoch: 21 starting with accuracy 0.29772727272727273\n",
            "Epoch: 22 starting with accuracy 0.3255681818181818\n",
            "Epoch: 23 starting with accuracy 0.3315340909090909\n",
            "Epoch: 24 starting with accuracy 0.30227272727272725\n",
            "Epoch: 25 starting with accuracy 0.30880681818181815\n",
            "Epoch: 26 starting with accuracy 0.3255681818181818\n",
            "Epoch: 27 starting with accuracy 0.3482954545454545\n",
            "Epoch: 28 starting with accuracy 0.30227272727272725\n",
            "Epoch: 29 starting with accuracy 0.32073863636363636\n",
            "Epoch: 30 starting with accuracy 0.3164772727272728\n",
            "Epoch: 31 starting with accuracy 0.33636363636363636\n",
            "Epoch: 32 starting with accuracy 0.31931818181818183\n",
            "Epoch: 33 starting with accuracy 0.33607954545454544\n",
            "Epoch: 34 starting with accuracy 0.33636363636363636\n",
            "Epoch: 35 starting with accuracy 0.31107954545454547\n",
            "Epoch: 36 starting with accuracy 0.31931818181818183\n",
            "Epoch: 37 starting with accuracy 0.3321022727272728\n",
            "Epoch: 38 starting with accuracy 0.31789772727272725\n",
            "Epoch: 39 starting with accuracy 0.33636363636363636\n",
            "Epoch: 40 starting with accuracy 0.34090909090909094\n",
            "Epoch: 41 starting with accuracy 0.340625\n",
            "Epoch: 42 starting with accuracy 0.3221590909090909\n",
            "Epoch: 43 starting with accuracy 0.3392045454545455\n",
            "Epoch: 44 starting with accuracy 0.3301136363636364\n",
            "Epoch: 45 starting with accuracy 0.3241477272727272\n",
            "Epoch: 46 starting with accuracy 0.31732954545454545\n",
            "Epoch: 47 starting with accuracy 0.3241477272727272\n",
            "Epoch: 48 starting with accuracy 0.3457386363636364\n",
            "Epoch: 49 starting with accuracy 0.32272727272727275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize accuracy and loss for training and test data.\n",
        "plt.figure()\n",
        "line1, = plt.plot(train_losses)\n",
        "line2, = plt.plot(test_losses)\n",
        "line3, = plt.plot(test_accuracies)\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend((line1,line2, line3),(\"training\",\"test\", \"test accuracy\"))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "VoX7R4ZiXHtT",
        "outputId": "8292519f-1092-40d8-fde9-525a5a796815"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9c946f1c1094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Visualize accuracy and loss for training and test data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mline1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mline2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mline3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZG-8KrHmXHwK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}